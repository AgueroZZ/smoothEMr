% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/07_partition.R
\name{forward_two_ordering_partition_csmooth}
\alias{forward_two_ordering_partition_csmooth}
\title{Forward greedy feature partition into two orderings (csmoothEM version)}
\usage{
forward_two_ordering_partition_csmooth(
  X,
  K = 30,
  greedy_start_index = NULL,
  greedy_start_index2 = NULL,
  score_mode = c("ml", "none"),
  rw_q = 2,
  relative_lambda = TRUE,
  lambda_min = 1e-10,
  lambda_max = 1e+10,
  greedy_em_refine = TRUE,
  greedy_em_max_iter = 10,
  discretization = c("quantile", "equal", "kmeans"),
  verbose = 1
)
}
\arguments{
\item{X}{Numeric matrix \code{(n x d)}.}

\item{K}{Integer \eqn{\ge 2}. Number of mixture components.}

\item{greedy_start_index}{Optional integer. First seed feature. If NULL, uses the largest-variance feature.}

\item{greedy_start_index2}{Optional integer. Second seed feature. If NULL, chosen as worst under ordering 1.}

\item{score_mode}{One of \code{"ml"} or \code{"none"}.}

\item{rw_q}{Integer \eqn{\ge 0}. Rank deficiency along K (RW order).}

\item{relative_lambda}{Logical; whether relative-lambda scaling is used.}

\item{lambda_min, lambda_max}{Bounds for lambda optimization when \code{score_mode="ml"}.}

\item{greedy_em_refine}{Logical; if TRUE, run short csmoothEM refinement after each append.}

\item{greedy_em_max_iter}{Integer \eqn{\ge 0}. Number of refinement iterations per append.
Set to 0 to disable refinement even if \code{greedy_em_refine=TRUE}.}

\item{discretization}{Discretization method used in seed initialization (recommended: \code{"quantile"}).}

\item{verbose}{Integer. \code{0}=silent, \code{1}=progress messages.}
}
\value{
A list with:
\itemize{
  \item \code{coord_assign}: integer vector length d with values 1 or 2.
  \item \code{J1}, \code{J2}: feature indices in each ordering.
  \item \code{Gamma1}, \code{Gamma2}: responsibilities after greedy completion.
  \item \code{params1}, \code{params2}: csmooth-style params for each ordering.
  \item \code{fit1}, \code{fit2}: \code{csmooth_em} objects for each ordering (ready for further refinement).
  \item \code{seeds}: list with \code{j1}, \code{j2}.
}
}
\description{
Greedily partitions features (columns of \code{X}) into two groups, each associated with
its own latent ordering (represented by responsibilities \eqn{\Gamma} over \code{K} components).

The algorithm mirrors the structure of \code{two_ordering_smoothEM_v2}:
\enumerate{
  \item Choose a seed feature \code{j1} (largest variance by default) and fit a 1D csmoothEM model
        on \code{X[, j1]} to obtain \eqn{\Gamma_1} and parameters \eqn{\theta_1}.
  \item Choose a second seed feature \code{j2} as the feature with the worst alignment score
        under \eqn{\Gamma_1}, then fit a 1D model on \code{X[, j2]} to obtain \eqn{\Gamma_2} and \eqn{\theta_2}.
  \item While unassigned features remain:
    \itemize{
      \item Score each remaining feature under \eqn{\Gamma_1} and \eqn{\Gamma_2}.
      \item Select the feature with the largest absolute score gap and assign it to the better ordering.
      \item Append the 1D fitted object to that ordering's parameters and update \eqn{\Gamma} by an E-step.
      \item Optionally run a short csmoothEM refinement on that ordering (controlled by \code{greedy_em_refine}).
    }
}

Scoring:
\itemize{
  \item \code{score_mode="none"} uses a plug-in (ELBO/Q-like) score with fixed \eqn{\lambda=1}.
  \item \code{score_mode="ml"} uses a collapsed (marginal-like) score with \eqn{\lambda} optimized per feature.
}
}
\seealso{
\code{\link{do_csmoothEM}}, \code{\link{score_feature_given_Gamma}}, \code{\link{compute_C_by_coord_csmooth}}
}
