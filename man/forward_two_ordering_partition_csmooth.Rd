% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/07_partition.R
\name{forward_two_ordering_partition_csmooth}
\alias{forward_two_ordering_partition_csmooth}
\title{Forward greedy feature partition into two orderings (csmoothEM version)}
\usage{
forward_two_ordering_partition_csmooth(
  X,
  K = 30,
  greedy_start_index = NULL,
  greedy_start_index2 = NULL,
  seeding = c("variance", "correlation"),
  seed_ordering_vec = NULL,
  seed_pc_scale = TRUE,
  seed_cor_abs = TRUE,
  score_mode = c("ml", "none"),
  rw_q = 2,
  relative_lambda = TRUE,
  lambda_min = 1e-10,
  lambda_max = 1e+10,
  greedy_em_refine = TRUE,
  greedy_em_max_iter = 10,
  discretization = c("quantile", "equal", "kmeans"),
  verbose = 1
)
}
\arguments{
\item{X}{Numeric matrix \code{(n x d)}.}

\item{K}{Integer \eqn{\ge 2}. Number of mixture components.}

\item{greedy_start_index}{Optional integer. First seed feature. If NULL, chosen by \code{seeding}.}

\item{greedy_start_index2}{Optional integer. Second seed feature. If NULL, chosen by \code{seeding} rule above.}

\item{seeding}{Seeding strategy when \code{greedy_start_index} is NULL.
\describe{
  \item{\code{"variance"}}{Use the maximum-variance feature as the first seed (default).}
  \item{\code{"correlation"}}{Use correlation with an ordering vector to choose seeds.}
}}

\item{seed_ordering_vec}{Optional numeric vector of length \code{n}. Only used when
\code{seeding="correlation"} and \code{greedy_start_index} is NULL.
If NULL, defaults to the first PC score of \code{X}.}

\item{seed_pc_scale}{Logical; only used when \code{seed_ordering_vec} is NULL and
\code{seeding="correlation"}. Passed as \code{scale.} to \code{prcomp}.}

\item{seed_cor_abs}{Logical; if TRUE (default) seed using absolute correlations.
If FALSE, use signed correlations (max/min correlation).}

\item{score_mode}{One of \code{"ml"} or \code{"none"}.}

\item{rw_q}{Integer \eqn{\ge 0}. Rank deficiency along K (RW order).}

\item{relative_lambda}{Logical; whether relative-lambda scaling is used.}

\item{lambda_min, lambda_max}{Bounds for lambda optimization when \code{score_mode="ml"}.}

\item{greedy_em_refine}{Logical; if TRUE, run short csmoothEM refinement after each append.}

\item{greedy_em_max_iter}{Integer \eqn{\ge 0}. Number of refinement iterations per append.
Set to 0 to disable refinement even if \code{greedy_em_refine=TRUE}.}

\item{discretization}{Discretization method used in seed initialization (recommended: \code{"quantile"}).}

\item{verbose}{Integer. \code{0}=silent, \code{1}=progress messages.}
}
\value{
A list with:
\itemize{
  \item \code{coord_assign}: integer vector length d with values 1 or 2.
  \item \code{J1}, \code{J2}: feature indices in each ordering.
  \item \code{Gamma1}, \code{Gamma2}: responsibilities after greedy completion.
  \item \code{params1}, \code{params2}: csmooth-style params for each ordering.
  \item \code{fit1}, \code{fit2}: \code{csmooth_em} objects for each ordering (ready for further refinement).
  \item \code{seeds}: list with \code{j1}, \code{j2}.
}
}
\description{
Greedily partitions features (columns of \code{X}) into two groups, each associated with
its own latent ordering (represented by responsibilities \eqn{\Gamma} over \code{K} components).

The algorithm mirrors the structure of \code{two_ordering_smoothEM_v2}:
\enumerate{
  \item Choose a seed feature \code{j1} and fit a 1D csmoothEM model on \code{X[, j1]}
        to obtain \eqn{\Gamma_1} and parameters \eqn{\theta_1}.
  \item Choose a second seed feature \code{j2} and fit a 1D csmoothEM model on \code{X[, j2]}
        to obtain \eqn{\Gamma_2} and parameters \eqn{\theta_2}.
  \item While unassigned features remain:
    \itemize{
      \item Score each remaining feature under \eqn{\Gamma_1} and \eqn{\Gamma_2}.
      \item Select the feature with the largest absolute score gap and assign it to the better ordering.
      \item Append the 1D fitted object to that ordering's parameters and update \eqn{\Gamma} by an E-step.
      \item Optionally run a short csmoothEM refinement on that ordering (controlled by \code{greedy_em_refine}).
    }
}

Seeding:
\itemize{
  \item If \code{greedy_start_index} is provided, it is used as \code{j1}.
  \item Otherwise, \code{seeding="variance"} chooses \code{j1} as the maximum-variance feature.
  \item Otherwise, \code{seeding="correlation"} chooses \code{j1} as the feature most correlated
        (by default, absolute correlation) with an ordering vector \code{seed_ordering_vec}.
        If \code{seed_ordering_vec} is NULL, the ordering vector defaults to the first PC score of \code{X}.
}

For \code{j2}:
\itemize{
  \item If \code{greedy_start_index2} is provided, it is used as \code{j2}.
  \item Else if \code{seeding="correlation"} and \code{greedy_start_index} is NULL, choose \code{j2}
        as the feature least correlated with the same ordering vector used for \code{j1}.
  \item Else (default), choose \code{j2} as the feature with the worst alignment score under \eqn{\Gamma_1}.
}

Scoring:
\itemize{
  \item \code{score_mode="none"} uses a plug-in (ELBO/Q-like) score with fixed \eqn{\lambda=1}.
  \item \code{score_mode="ml"} uses a collapsed (marginal-like) score with \eqn{\lambda} optimized per feature.
}
}
\seealso{
\code{\link{do_csmoothEM}}, \code{\link{score_feature_given_Gamma}}, \code{\link{compute_C_by_coord_csmooth}}
}
