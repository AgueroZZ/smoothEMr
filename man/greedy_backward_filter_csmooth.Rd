% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/07_partition.R
\name{greedy_backward_filter_csmooth}
\alias{greedy_backward_filter_csmooth}
\title{Greedy backward filtering of features for csmoothEM ordering inference}
\usage{
greedy_backward_filter_csmooth(
  X,
  method = c("fiedler", "PCA", "tSNE", "pcurve", "random"),
  K = 50,
  modelName = c("homoskedastic", "heteroskedastic"),
  adaptive = "prior",
  num_iter_init = 10,
  num_iter_refit = 5,
  discretization = c("equal", "quantile", "kmeans"),
  batch = 20,
  min_keep = 20,
  tau = NULL,
  max_rounds = 50,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{X}{Numeric matrix \code{(n x d)}.}

\item{method}{Ordering method passed to \code{\link{initialize_csmoothEM}}. One of
\code{"fiedler"}, \code{"PCA"}, \code{"tSNE"}, \code{"pcurve"}, \code{"random"}.}

\item{K}{Integer \eqn{\ge 2}. Number of mixture components.}

\item{modelName}{Either \code{"homoskedastic"} or \code{"heteroskedastic"}.}

\item{adaptive}{Adaptive mode passed to \code{\link{do_csmoothEM}} when refitting.
Typically \code{"prior"} for speed (or \code{"ml"} if using collapsed-ML).}

\item{num_iter_init}{Integer \eqn{\ge 1}. Number of warm-start iterations for the initial fit.}

\item{num_iter_refit}{Integer \eqn{\ge 1}. Number of iterations for each refit after feature removal.}

\item{discretization}{Discretization method for initialization passed to \code{initialize_csmoothEM}.
Recommended: \code{"quantile"} to avoid empty components.}

\item{batch}{Integer \eqn{\ge 1}. Number of lowest-scoring features (smallest \eqn{C_j}) removed per round.}

\item{min_keep}{Integer \eqn{\ge 1}. Minimum number of features to keep; stops if fewer would remain.}

\item{tau}{Optional numeric threshold. If provided, stops when \code{min(Cj) >= tau}.}

\item{max_rounds}{Integer \eqn{\ge 1}. Maximum number of greedy rounds.}

\item{verbose}{Logical; print a one-line summary each round.}

\item{...}{Additional arguments passed to \code{initialize_csmoothEM} (e.g. ordering controls).}
}
\value{
A list with components:
\itemize{
  \item \code{keep_cols}: integer indices of retained features (w.r.t. the original X).
  \item \code{drop_cols}: integer indices of removed features (w.r.t. the original X).
  \item \code{fit}: final fitted \code{csmooth_em} object on the retained features.
  \item \code{history}: data.frame with per-round diagnostics (\code{C_total}, \code{min_Cj}, etc.).
}
}
\description{
Implements a greedy "backward" feature filtering strategy to mitigate the case where
most features are noise and do not follow any latent ordering. The algorithm:
\enumerate{
  \item Fits csmoothEM on all features to obtain an initial ordering (via responsibilities \eqn{\Gamma}).
  \item Computes per-feature collapsed contributions \eqn{C_j} (via \code{compute_C_by_coord_csmooth}).
  \item Removes a batch of features with the smallest \eqn{C_j}.
  \item Refits csmoothEM on the remaining features for a few iterations.
  \item Repeats until a stopping rule is met.
}

This procedure is intended as a preprocessing step before more ambitious tasks such as
feature partitioning across multiple orderings.
}
