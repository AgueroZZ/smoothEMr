% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/03_SmoothEM.R
\name{compute_log_joint_observed}
\alias{compute_log_joint_observed}
\alias{compute_penalized_ELBO}
\alias{ESTEP}
\alias{MSTEP}
\alias{EM_algorithm}
\title{Internal E-step for SmoothEM}
\usage{
compute_log_joint_observed(
  X,
  params,
  Q_prior = NULL,
  eigen_tol = NULL,
  rank_deficiency = 0,
  Q_base = NULL,
  lambda = NULL
)

compute_penalized_ELBO(
  X,
  Gamma,
  params,
  Q_prior = NULL,
  eigen_tol = NULL,
  rank_deficiency = 0,
  Q_base = NULL,
  lambda = NULL
)

ESTEP(data, params)

MSTEP(
  data,
  gamma,
  params,
  Q_prior = NULL,
  relative_lambda = FALSE,
  modelName = "VVV",
  iterate_once = TRUE,
  nugget = 0,
  rank_deficiency = 0,
  tol_inner = 1e-06,
  max_inner = 20,
  verbose = FALSE
)

EM_algorithm(
  data,
  init_params,
  Q_prior = NULL,
  iterate_once = TRUE,
  max_inner = 10,
  modelName = "VVV",
  max_iter = 100,
  tol = 1e-04,
  inner_tol = 1e-06,
  eigen_tol = NULL,
  rank_deficiency = 0,
  nugget = 0,
  relative_lambda = FALSE,
  verbose = TRUE,
  include.data = TRUE
)
}
\arguments{
\item{params}{Current parameter list (used mainly for starting \code{sigma}).}

\item{Q_prior}{Optional precision matrix on stacked means (\code{d*K x d*K}).}

\item{eigen_tol}{Optional tolerance passed to \code{generalized_logdet()}.}

\item{rank_deficiency}{Rank deficiency for pseudo-determinant correction (commonly \code{q*d}).}

\item{data}{Numeric matrix \code{(n x d)} of observations.}

\item{gamma}{Numeric matrix \code{(n x K)} responsibilities.}

\item{relative_lambda}{Logical; if TRUE, rescales \code{Q_prior} by current marginal variances.}

\item{modelName}{Covariance model: one of \code{"VVV"}, \code{"VII"}, \code{"EII"}, \code{"EEI"}.}

\item{iterate_once}{Logical; if TRUE, stop after one EM iteration (often used inside wrappers).}

\item{nugget}{Nonnegative diagonal jitter added to covariance estimates.}

\item{tol_inner, max_inner}{Inner-loop controls when iterating \code{mu <-> sigma}.}

\item{max_inner}{Maximum number of inner iterations inside the M-step.}

\item{verbose}{Logical; print progress.}

\item{init_params}{Initial parameters as a list with \code{pi}, \code{mu}, \code{sigma}.}

\item{max_iter}{Maximum number of EM iterations.}

\item{tol}{Convergence tolerance on ELBO changes.}

\item{inner_tol}{Tolerance for inner iterations inside the M-step.}

\item{include.data}{Logical; if TRUE, include \code{data} in the returned list.}
}
\value{
Numeric matrix \code{(n x K)} of responsibilities.

List with updated \code{pi}, \code{mu}, \code{sigma}.

A list with:
\itemize{
  \item \code{params}: final parameters (including cached \code{invSigma} and \code{logdet}).
  \item \code{gamma}: responsibility matrix \code{(n x K)}.
  \item \code{elbo_trace}: numeric vector.
  \item \code{loglik_trace}: numeric vector.
}
}
\description{
Computes responsibilities \eqn{\gamma_{ik}} given current parameters.
Expects \code{params$invSigma} and \code{params$logdet} to be precomputed
(see \code{init_cov_cache_fast()}).

Updates mixture parameters given responsibilities, optionally with a quadratic
prior penalty on stacked means via \code{Q_prior}. Supports covariance models:
\code{"VVV"}, \code{"VII"}, \code{"EII"}, \code{"EEI"}.

Fits a Gaussian mixture model with optional quadratic prior penalty on the stacked
mean vector \code{mu}. The algorithm alternates E-steps and penalized M-steps and
records both a penalized observed-data objective and a penalized ELBO trace.
}
\keyword{internal}
